use std::{
    collections::{hash_map::DefaultHasher, HashMap, HashSet},
    hash::{self, Hash, Hasher},
};

use daggy::{
    petgraph::visit::{EdgeRef, IntoEdgeReferences},
    EdgeIndex,
};
use rand::{thread_rng, Rng};

use crate::{
    fn_dag::FnId,
    node::NodeId,
    request::{ReqId, Request},
    scale_executor::{ScaleExecutor, ScaleOption},
    schedule::Scheduler,
    sim_env::SimEnv,
    util,
};

struct RequestSchedulePlan {
    fn_nodes: HashMap<FnId, NodeId>,
}

pub struct FaasFlowScheduler {
    // request_schedule_state: HashMap<ReqId, RequestSchedulePlan>,
    scheduled_reqs: HashSet<ReqId>,
}

impl FaasFlowScheduler {
    pub fn new() -> Self {
        Self {
            scheduled_reqs: HashSet::new(),
        }
    }

    fn schedule_one_req(&mut self, req: &mut Request, env: &SimEnv) {
        log::info!("faasflow start generate schedule for req {}", req.req_id);
        let mut nodes_left_mem = env
            .nodes
            .borrow()
            .iter()
            .map(|n| n.left_mem_for_place_container())
            .collect::<Vec<_>>();
        //1.ä¸ºè¯·æ±‚çš„æ‰€æœ‰å‡½æ•°éšæœºåˆ†é…èŠ‚ç‚¹
        let mut fn_poses = HashMap::new();
        {
            let dag = env.dag(req.dag_i);
            let mut walker = dag.new_dag_walker();
            while let Some(fnode) = walker.next(&dag.dag_inner) {
                let fnid = dag.dag_inner[fnode];
                let mut hasher = DefaultHasher::new();
                fnid.hash(&mut hasher);
                let node_id = hasher.finish() as usize % env.node_cnt(); //thread_rng().gen_range(0..nodes_left_mem.len());
                                                                         // let node_id = (0, nodes_left_mem.len());
                fn_poses.insert(fnid, node_id);
                nodes_left_mem[node_id] -= env.func(fnid).container_mem();
            }
        }
        //2.éå†æ”¶é›†å…³é”®è·¯å¾„
        let dag = env.dag(req.dag_i);
        let critical_path_nodes = util::graph::critical_path(&dag.dag_inner);
        log::info!("C");
        let mut cri_paths = vec![];
        for i in 0..critical_path_nodes.len() - 1 {
            cri_paths.push(
                dag.dag_inner
                    .find_edge(critical_path_nodes[i], critical_path_nodes[i + 1])
                    .unwrap(),
            );
            // non_cti_paths.remove(&(critical_path_nodes[i], critical_path_nodes[i+1]));
        }
        let mut non_cri_paths = dag
            .dag_inner
            .edge_references()
            .map(|e| e.id())
            .filter(|e| !cri_paths.contains(e))
            .collect::<Vec<_>>();
        let cmp_edge = |e1: &EdgeIndex, e2: &EdgeIndex| {
            let e1_weight = *dag.dag_inner.edge_weight(*e1).unwrap();
            let e2_weight = *dag.dag_inner.edge_weight(*e2).unwrap();
            e2_weight.partial_cmp(&e1_weight).unwrap()
        };
        cri_paths.sort_by(cmp_edge);
        non_cri_paths.sort_by(cmp_edge);

        if cri_paths.len() > 1 {
            assert!(
                *dag.dag_inner.edge_weight(cri_paths[0]).unwrap()
                    >= *dag.dag_inner.edge_weight(cri_paths[1]).unwrap()
            );
        }

        let mut try_merge_e = |e: EdgeIndex| {
            let (nbegin, nend) = dag.dag_inner.edge_endpoints(e).unwrap();
            let fnbegin = dag.dag_inner[nbegin];
            let fnend = dag.dag_inner[nend];
            let old_node_begin = *fn_poses.get(&fnbegin).unwrap();
            let old_node_end = *fn_poses.get(&fnend).unwrap();
            if old_node_begin == old_node_end {
                return;
            }
            if nodes_left_mem[old_node_begin] > env.func(fnend).container_mem() {
                nodes_left_mem[old_node_begin] -= env.func(fnend).container_mem();
                nodes_left_mem[old_node_end] += env.func(fnend).container_mem();
                fn_poses.insert(fnend, old_node_begin);
            }
        };

        for e in cri_paths {
            try_merge_e(e);
        }
        for e in non_cri_paths {
            try_merge_e(e);
        }

        // self.request_schedule_state
        //     .insert(req.req_id, RequestSchedulePlan { fn_nodes: fn_poses });
        log::info!("faasflow end generate schedule for req {}", req.req_id);
        for (fnid, nodeid) in fn_poses {
            env.schedule_reqfn_on_node(req, fnid, nodeid)
        }
        self.scheduled_reqs.insert(req.req_id);
    }

    // fn do_some_schedule(&self, req: &mut Request, env: &SimEnv) {
    //     let dag = env.dag(req.dag_i);
    //     let plan = self.request_schedule_state.get(&req.req_id).unwrap();
    //     let mut walker = dag.new_dag_walker();
    //     while let Some(fnode) = walker.next(&dag.dag_inner) {
    //         let fnid = dag.dag_inner[fnode];
    //         // Already scheduled
    //         if req.get_fn_node(fnid).is_some() {
    //             continue;
    //         }
    //         // Not schduled but not all parents done
    //         if !req.parents_all_done(env, fnid) {
    //             continue;
    //         }
    //         // Ready to be scheduled
    //         let fn_node = *plan.fn_nodes.get(&fnid).unwrap();
    //         if env.node(fn_node).container(fnid).is_none() {
    //             if env
    //                 .scale_executor
    //                 .borrow_mut()
    //                 .scale_up_fn_to_nodes(env, fnid, &vec![fn_node])
    //                 == 0
    //             {
    //                 continue;
    //             }
    //         }
    //         // if env.node(fn_node).mem_enough_for_container(&env.func(fnid)) {
    //         env.schedule_reqfn_on_node(req, fnid, fn_node);
    //         // }
    //     }
    // }

    fn schedule_for_one_req(&mut self, req: &mut Request, env: &SimEnv) {
        if !self.scheduled_reqs.contains(&req.req_id) {
            self.schedule_one_req(req, env);
        }
        // self.do_some_schedule(req, env);
    }
}

// å›¾å½¢è°ƒåº¦å™¨ä¸­åˆ†ç»„å’Œè°ƒåº¦ç®—æ³•çš„å…³é”®æ­¥éª¤å¦‚ä¸‹æ‰€ç¤ºã€‚
// åœ¨åˆå§‹åŒ–é˜¶æ®µï¼Œæ¯ä¸ªå‡½æ•°èŠ‚ç‚¹éƒ½ä½œä¸ºå•ç‹¬çš„ç»„è¿›è¡Œåˆå§‹åŒ–ï¼Œå¹¶ä¸”å·¥ä½œèŠ‚ç‚¹æ˜¯éšæœºåˆ†é…çš„ï¼ˆç¬¬1-2è¡Œï¼‰ã€‚
// é¦–å…ˆï¼Œç®—æ³•ä»æ‹“æ‰‘æ’åºå’Œè¿­ä»£å¼€å§‹ã€‚åœ¨æ¯æ¬¡è¿­ä»£çš„å¼€å§‹ï¼Œå®ƒå°†ä½¿ç”¨è´ªå©ªæ–¹æ³•æ¥å®šä½DAGå›¾ä¸­å…³é”®è·¯å¾„ä¸Šå…·æœ‰æœ€é•¿è¾¹çš„ä¸¤ä¸ªå‡½æ•°ï¼Œ
// å¹¶ç¡®å®šè¿™ä¸¤ä¸ªå‡½æ•°æ˜¯å¦å¯ä»¥åˆå¹¶åˆ°åŒä¸€ç»„ï¼ˆç¬¬3-8è¡Œï¼‰ã€‚
// å¦‚æœè¿™ä¸¤ä¸ªå‡½æ•°è¢«åˆ†é…åˆ°ä¸åŒçš„ç»„ä¸­ï¼Œå®ƒä»¬å°†è¢«åˆå¹¶ï¼ˆç¬¬9è¡Œï¼‰ã€‚
// åœ¨åˆå¹¶ç»„æ—¶ï¼Œéœ€è¦è€ƒè™‘é¢å¤–çš„å› ç´ ã€‚
//  é¦–å…ˆï¼Œç®—æ³•éœ€è¦ç¡®ä¿åˆå¹¶çš„å‡½æ•°ç»„ä¸è¶…è¿‡å·¥ä½œèŠ‚ç‚¹çš„æœ€å¤§å®¹é‡ï¼ˆç¬¬10-12è¡Œï¼‰ã€‚
//  å¦åˆ™ï¼Œåˆå¹¶çš„ç»„å°†æ— æ³•éƒ¨ç½²åœ¨ä»»ä½•èŠ‚ç‚¹ä¸Šã€‚å…¶æ¬¡ï¼Œç»„å†…å±€éƒ¨åŒ–çš„æ•°æ®æ€»é‡ä¸èƒ½è¿åå†…å­˜çº¦æŸï¼ˆç¬¬13-18è¡Œï¼‰ã€‚
//  åŒæ—¶ï¼Œåœ¨åˆå¹¶çš„ç»„ä¸­ä¸èƒ½å­˜åœ¨ä»»ä½•èµ„æºç«äº‰çš„å‡½æ•°å¯¹ğ‘ğ‘œğ‘›ğ‘¡ (ğº) = {(ğ‘“ğ‘–, ğ‘“ğ‘— )}ï¼ˆç¬¬19-20è¡Œï¼‰ã€‚
//  æœ€åï¼Œè°ƒåº¦ç®—æ³•å°†é‡‡ç”¨è£…ç®±ç­–ç•¥ï¼Œæ ¹æ®èŠ‚ç‚¹å®¹é‡ä¸ºæ¯ä¸ªå‡½æ•°ç»„é€‰æ‹©é€‚å½“çš„å·¥ä½œèŠ‚ç‚¹ï¼ˆç¬¬21-23è¡Œï¼‰ã€‚
// æ ¹æ®ä¸Šè¿°é€»è¾‘ï¼Œç®—æ³•è¿­ä»£ç›´åˆ°æ”¶æ•›ï¼Œè¡¨ç¤ºå‡½æ•°ç»„ä¸å†æ›´æ–°ã€‚
impl Scheduler for FaasFlowScheduler {
    fn schedule_some(&mut self, env: &SimEnv) {
        for (_, req) in env.requests.borrow_mut().iter_mut() {
            self.schedule_for_one_req(req, env);
        }

        let mut to_scale_down = vec![];
        // å›æ”¶ç©ºé—²container
        for n in env.nodes.borrow().iter() {
            for (_, c) in n.fn_containers.borrow().iter() {
                if c.recent_frame_is_idle(3) && c.req_fn_state.len() == 0 {
                    to_scale_down.push((n.node_id(), c.fn_id));
                }
            }
        }
        for (n, f) in to_scale_down {
            env.scale_executor
                .borrow_mut()
                .scale_down(env, ScaleOption::ForSpecNodeFn(n, f));
        }
    }

    fn prepare_this_turn_will_schedule(&mut self, env: &SimEnv) {}

    fn this_turn_will_schedule(&self, fnid: FnId) -> bool {
        panic!("not support");
    }
}
